{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2bf8ef6-7628-4777-ac19-018978c273cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from jcopml.pipeline import num_pipe, cat_pipe\n",
    "from jcopml.utils import save_model, load_model\n",
    "from jcopml.plot import plot_missing_value\n",
    "from jcopml.feature_importance import mean_score_decrease\n",
    "\n",
    "from luwiji.text_proc import illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bb312b2-b69a-4862-ac29-ec4336bcff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "sw_indo = stopwords.words(\"indonesian\") + list(punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8e1802-2493-43c9-97bb-2a03c85f03eb",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ea034fe-aa3e-480e-be81-f17155d90410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apa aplikasi yang bagus untuk dengan mudah per...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aplikasi ini banyak membantu saya. Sekarang sa...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mengerikan. Antarmukanya sangat membingungkan....</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aplikasi yang cukup mengesankan. Butuh waktu l...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aplikasi ini sebenarnya bagus dan sangat memba...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review      rate\n",
       "0  Apa aplikasi yang bagus untuk dengan mudah per...  positive\n",
       "1  Aplikasi ini banyak membantu saya. Sekarang sa...  positive\n",
       "2  Mengerikan. Antarmukanya sangat membingungkan....  negative\n",
       "3  Aplikasi yang cukup mengesankan. Butuh waktu l...  positive\n",
       "4  Aplikasi ini sebenarnya bagus dan sangat memba...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/gojek_review_sentiment.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9148a815-84d9-4ffb-9845-c5413c2e4364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rate\n",
       "negative    0.595398\n",
       "positive    0.404602\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rate.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fd7cd8-7ae9-4a9a-b825-5a806f6af99b",
   "metadata": {},
   "source": [
    "# Dataset Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa27788e-b895-455f-96dc-3e2c39417d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1425,), (357,), (1425,), (357,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.review\n",
    "y = df.rate\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c27965-1680-4118-b2ed-bbf36cde46a4",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "794ce0dc-86be-463c-a369-265be8b202fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from jcopml.tuning import random_search_params as rsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ac4577f-a462-4843-b90a-71a30125c54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/zaens/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo__C': 1.368979599359222, 'algo__gamma': 0.36749049453053273}\n",
      "0.9585964912280702 0.89472586787524 0.8907563025210085\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"prep\", TfidfVectorizer(tokenizer=word_tokenize, stop_words=sw_indo)),\n",
    "    (\"algo\", SVC(max_iter=500))\n",
    "])\n",
    "model = RandomizedSearchCV(pipeline, rsp.svm_params, cv=4, n_iter=50, n_jobs=-1, verbose=1, random_state=42)\n",
    "model.fit(X_train, y_train);\n",
    "\n",
    "print(model.best_params_)\n",
    "print(model.score(X_train, y_train), model.best_score_, model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f91dd8b-6a68-4e26-98dd-0b35801c4e3c",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10546902-80ef-4b44-8ba4-a3eae3428798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jcopml.plot import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "346610b3-8a53-470c-b060-e83318cb221b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(X_train, y_train, X_test, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba45de2-5033-43fd-a4bc-3eda2df75c18",
   "metadata": {},
   "source": [
    "# Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a64d681b-58b1-46a2-bd87-8a3be7c70e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [\"aplikasi kaya anjing enak banget\"]\n",
    "model.predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe24deb-1662-4628-871e-ad8e8efb43d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7ab6df-66dc-4d0b-ba3b-3d2da7b7b520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cb0fd8-af99-4e36-8e77-121ae0897110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3273530-c01a-4d86-b55f-d9ca5390d24a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c87c71f-0ff2-4da8-949e-c59efdc3b94e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb297ed-4e44-44b5-bbfd-d2487232c5a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99910318-71a6-49c5-adb6-04d829c99342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47485d15-3914-4e49-828d-3820c633601b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5323c1-df26-4158-9240-2cc86fd62669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d3b7c5-bb71-4a81-9bbd-60717f9a688d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d22023-90ea-4fec-9b46-7cc0d1e5c1b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff7c45b-71a3-47a3-ac46-d46eefc0dd52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa5e879-f7ec-45b3-9a6c-cfc5d39a37bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc760f4-add5-470e-8651-fb7d69154bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6888a2d9-4382-49bc-bdc0-07d6585063b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722b25b9-3e20-4374-9589-694f2628c68d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88917c3-3b0e-4dbd-8961-8f20733e7040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5272b270-6652-4c91-bf1f-9157737397bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
