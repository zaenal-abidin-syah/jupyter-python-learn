{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d2DegsYIgrHr"
   },
   "outputs": [],
   "source": [
    "# !pip install jcopdl gdown\n",
    "# !gdown https://drive.google.com/uc?id=1KaiwyyYRGW8FbvSd4Feg1i1YW2k2s30u\n",
    "# !unzip /content/celebA_redux.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HGpzFWM3fG31",
    "outputId": "92a25837-f27f-4546-e9e9-8107b82b713e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from jcopdl.callback import Callback, set_config\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8KiSL1MrfG35"
   },
   "source": [
    "# Dataset & Dataloader (Hanya Train set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7-Zfd6T4fG35"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DA1TW9MvfG38"
   },
   "outputs": [],
   "source": [
    "bs = 64\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]) # menjadi (-1, 1)\n",
    "])\n",
    "\n",
    "train_set = datasets.ImageFolder(\"celebA_redux/celebA_redux/\", transform=transform)\n",
    "trainloader = DataLoader(train_set, batch_size=bs, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2jmUnJ5UfG3-"
   },
   "source": [
    "# Arsitektur & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.10'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jcopdl\n",
    "jcopdl.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: jcopdl 1.1.10\n",
      "Uninstalling jcopdl-1.1.10:\n",
      "  Successfully uninstalled jcopdl-1.1.10\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall jcopdl -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jcopdl==1.1.10\n",
      "  Using cached jcopdl-1.1.10-py2.py3-none-any.whl\n",
      "Requirement already satisfied: torch in /home/zaens/miniconda3/envs/MachineLearning/lib/python3.12/site-packages (from jcopdl==1.1.10) (2.5.1.post303)\n",
      "Requirement already satisfied: numpy in /home/zaens/miniconda3/envs/MachineLearning/lib/python3.12/site-packages (from jcopdl==1.1.10) (1.26.4)\n",
      "Requirement already satisfied: pandas in /home/zaens/miniconda3/envs/MachineLearning/lib/python3.12/site-packages (from jcopdl==1.1.10) (2.2.3)\n",
      "Requirement already satisfied: matplotlib in /home/zaens/miniconda3/envs/MachineLearning/lib/python3.12/site-packages (from jcopdl==1.1.10) (3.9.4)\n",
      "Requirement already satisfied: pillow in /home/zaens/miniconda3/envs/MachineLearning/lib/python3.12/site-packages (from jcopdl==1.1.10) (11.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/zaens/miniconda3/envs/MachineLearning/lib/python3.12/site-packages (from matplotlib->jcopdl==1.1.10) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/zaens/miniconda3/envs/MachineLearning/lib/python3.12/site-packages (from matplotlib->jcopdl==1.1.10) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/zaens/miniconda3/envs/MachineLearning/lib/python3.12/site-packages (from matplotlib->jcopdl==1.1.10) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/zaens/miniconda3/envs/MachineLearning/lib/python3.12/site-packages (from matplotlib->jcopdl==1.1.10) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/zaens/miniconda3/envs/MachineLearning/lib/python3.12/site-packages (from matplotlib->jcopdl==1.1.10) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/zaens/miniconda3/envs/MachineLearning/lib/python3.12/site-packages (from matplotlib->jcopdl==1.1.10) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/zaens/miniconda3/envs/MachineLearning/lib/python3.12/site-packages (from matplotlib->jcopdl==1.1.10) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/zaens/miniconda3/envs/MachineLearning/lib/python3.12/site-packages (from pandas->jcopdl==1.1.10) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/zaens/miniconda3/envs/MachineLearning/lib/python3.12/site-packages (from pandas->jcopdl==1.1.10) (2024.2)\n",
      "Requirement already satisfied: filelock in /home/zaens/miniconda3/envs/MachineLearning/lib/python3.12/site-packages (from torch->jcopdl==1.1.10) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/zaens/miniconda3/envs/MachineLearning/lib/python3.12/site-packages (from torch->jcopdl==1.1.10) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/zaens/miniconda3/envs/MachineLearning/lib/python3.12/site-packages (from torch->jcopdl==1.1.10) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/zaens/miniconda3/envs/MachineLearning/lib/python3.12/site-packages (from torch->jcopdl==1.1.10) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/zaens/miniconda3/envs/MachineLearning/lib/python3.12/site-packages (from torch->jcopdl==1.1.10) (2024.10.0)\n",
      "Requirement already satisfied: setuptools in /home/zaens/miniconda3/envs/MachineLearning/lib/python3.12/site-packages (from torch->jcopdl==1.1.10) (75.6.0)\n",
      "Requirement already satisfied: sympy!=1.13.2,>=1.13.1 in /home/zaens/miniconda3/envs/MachineLearning/lib/python3.12/site-packages (from torch->jcopdl==1.1.10) (1.13.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/zaens/miniconda3/envs/MachineLearning/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib->jcopdl==1.1.10) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/zaens/miniconda3/envs/MachineLearning/lib/python3.12/site-packages (from sympy!=1.13.2,>=1.13.1->torch->jcopdl==1.1.10) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/zaens/miniconda3/envs/MachineLearning/lib/python3.12/site-packages (from jinja2->torch->jcopdl==1.1.10) (3.0.2)\n",
      "Installing collected packages: jcopdl\n",
      "Successfully installed jcopdl-1.1.10\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade jcopdl==1.1.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MWXOXKz86WgO",
    "outputId": "cfbbbb02-6436-4b22-d6ac-0316f72612f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_wdcgan.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_wdcgan.py\n",
    "import torch\n",
    "from torch import nn\n",
    "from jcopdl.layers import conv_block, tconv_block, linear_block\n",
    "\n",
    "def conv(c_in, c_out, batch_norm=True, activation=\"lrelu\"):\n",
    "    return conv_block(c_in, c_out, kernel=4, stride=2, pad=1, bias=False, batch_norm=batch_norm, activation=activation, pool_type=None)\n",
    "\n",
    "def tconv(c_in, c_out, batch_norm=True, activation=\"lrelu\"):\n",
    "    return tconv_block(c_in, c_out, kernel=4, stride=2, pad=1, bias=False, batch_norm=batch_norm, activation=activation, pool_type=None)  \n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            conv(3, 32, batch_norm=False),          \n",
    "            conv(32, 64),\n",
    "            conv(64, 128),\n",
    "            conv(128, 256),\n",
    "            conv_block(256, 1, kernel=4, stride=1, pad=0, bias=False, activation=None, pool_type=None),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "    \n",
    "    def clip_weights(self, vmin=-0.01, vmax=0.01):\n",
    "        for p in self.parameters():\n",
    "            p.data.clamp_(vmin, vmax)    \n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        super().__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.tconv = nn.Sequential(\n",
    "            tconv_block(z_dim, 512, kernel=4, stride=2, pad=1, bias=False, activation=\"lrelu\", pool_type=None),\n",
    "            tconv(512, 256),\n",
    "            tconv(256, 128),\n",
    "            tconv(128, 64),\n",
    "            tconv(64, 32),\n",
    "            tconv(32, 3, activation=\"tanh\", batch_norm=False)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.tconv(x)\n",
    "\n",
    "    def generate(self, n, device):\n",
    "        z = torch.randn((n, self.z_dim, 1, 1), device=device)\n",
    "        return self.tconv(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kbNdKhoFfG4G"
   },
   "outputs": [],
   "source": [
    "config = set_config({\n",
    "    \"z_dim\": 100,\n",
    "    \"batch_size\": bs\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FUp8C9WLfG4I"
   },
   "source": [
    "# Training Preparation -> MCOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6UVaR9zCOu4"
   },
   "outputs": [],
   "source": [
    "from model_wdcgan import Critic, Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0p5r_GaqL0_r"
   },
   "outputs": [],
   "source": [
    "def wasserstein_loss(output, target):\n",
    "    return output.mean() * target.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tW1wM31CfG4J"
   },
   "outputs": [],
   "source": [
    "D = Critic().to(device)\n",
    "G = Generator(config.z_dim).to(device)\n",
    "\n",
    "criterion = wasserstein_loss\n",
    "\n",
    "d_optimizer = optim.RMSprop(D.parameters(), lr=1e-4)\n",
    "g_optimizer = optim.RMSprop(G.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZGvNxhjifG4L"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KsqZrS3E5TzE"
   },
   "outputs": [],
   "source": [
    "# !rm -rf /content/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1vFrvrads2YK"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision.utils import save_image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "os.makedirs(\"output/WDCGAN/\", exist_ok=True)\n",
    "os.makedirs(\"model/WDCGAN/\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7KP2mzSOpem2",
    "outputId": "22e2fca5-1e6c-49d6-e7ec-790403c10a3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     0 | D_loss: -0.19008 | G_loss: 0.20854\n",
      "Epoch:     5 | D_loss: -0.25356 | G_loss: 0.29609\n",
      "Epoch:    10 | D_loss: -0.27076 | G_loss: 0.31270\n",
      "Epoch:    15 | D_loss: -0.22399 | G_loss: 0.22184\n",
      "Epoch:    20 | D_loss: -0.16483 | G_loss: 0.10128\n",
      "Epoch:    25 | D_loss: -0.20062 | G_loss: 0.26080\n",
      "Epoch:    30 | D_loss: -0.18804 | G_loss: 0.26900\n",
      "Epoch:    35 | D_loss: -0.14951 | G_loss: 0.09250\n",
      "Epoch:    40 | D_loss: -0.11740 | G_loss: 0.08126\n",
      "Epoch:    45 | D_loss: -0.15283 | G_loss: 0.09500\n",
      "Epoch:    50 | D_loss: -0.12296 | G_loss: 0.22264\n",
      "Epoch:    55 | D_loss: -0.10538 | G_loss: 0.03324\n",
      "Epoch:    60 | D_loss: -0.11213 | G_loss: 0.20821\n",
      "Epoch:    65 | D_loss: -0.11334 | G_loss: 0.04439\n",
      "Epoch:    70 | D_loss: -0.11902 | G_loss: 0.06656\n",
      "Epoch:    75 | D_loss: -0.09465 | G_loss: 0.04598\n",
      "Epoch:    80 | D_loss: -0.12831 | G_loss: 0.02047\n",
      "Epoch:    85 | D_loss: -0.10817 | G_loss: 0.04513\n",
      "Epoch:    90 | D_loss: -0.10672 | G_loss: 0.12306\n",
      "Epoch:    95 | D_loss: -0.07999 | G_loss: 0.18913\n",
      "Epoch:   100 | D_loss: -0.09131 | G_loss: 0.18124\n",
      "Epoch:   105 | D_loss: -0.08989 | G_loss: 0.13839\n",
      "Epoch:   110 | D_loss: -0.07877 | G_loss: 0.16180\n",
      "Epoch:   115 | D_loss: -0.08749 | G_loss: 0.03939\n",
      "Epoch:   120 | D_loss: -0.08105 | G_loss: 0.03967\n",
      "Epoch:   125 | D_loss: -0.09283 | G_loss: 0.16955\n",
      "Epoch:   130 | D_loss: -0.07462 | G_loss: 0.00953\n",
      "Epoch:   135 | D_loss: -0.06486 | G_loss: 0.00792\n",
      "Epoch:   140 | D_loss: -0.07007 | G_loss: 0.15183\n",
      "Epoch:   145 | D_loss: -0.07278 | G_loss: 0.09072\n",
      "Epoch:   150 | D_loss: -0.07023 | G_loss: 0.04311\n",
      "Epoch:   155 | D_loss: -0.05869 | G_loss: 0.16771\n",
      "Epoch:   160 | D_loss: -0.06079 | G_loss: 0.18258\n",
      "Epoch:   165 | D_loss: -0.05436 | G_loss: 0.19203\n",
      "Epoch:   170 | D_loss: -0.07244 | G_loss: 0.06774\n",
      "Epoch:   175 | D_loss: -0.05996 | G_loss: 0.01540\n",
      "Epoch:   180 | D_loss: -0.06137 | G_loss: 0.18735\n",
      "Epoch:   185 | D_loss: -0.05860 | G_loss: 0.00596\n",
      "Epoch:   190 | D_loss: -0.05925 | G_loss: 0.07387\n",
      "Epoch:   195 | D_loss: -0.06423 | G_loss: 0.08003\n",
      "Epoch:   200 | D_loss: -0.06003 | G_loss: 0.03255\n",
      "Epoch:   205 | D_loss: -0.06539 | G_loss: 0.06957\n",
      "Epoch:   210 | D_loss: -0.06501 | G_loss: 0.16427\n",
      "Epoch:   215 | D_loss: -0.05685 | G_loss: 0.11720\n",
      "Epoch:   220 | D_loss: -0.04998 | G_loss: 0.12122\n",
      "Epoch:   225 | D_loss: -0.05089 | G_loss: 0.09190\n",
      "Epoch:   230 | D_loss: -0.05502 | G_loss: 0.07167\n",
      "Epoch:   235 | D_loss: -0.05260 | G_loss: 0.10434\n",
      "Epoch:   240 | D_loss: -0.05639 | G_loss: 0.03022\n",
      "Epoch:   245 | D_loss: -0.05118 | G_loss: -0.02444\n",
      "Epoch:   250 | D_loss: -0.04009 | G_loss: 0.13273\n",
      "Epoch:   255 | D_loss: -0.05697 | G_loss: 0.07228\n",
      "Epoch:   260 | D_loss: -0.05712 | G_loss: 0.09007\n",
      "Epoch:   265 | D_loss: -0.05233 | G_loss: 0.13515\n",
      "Epoch:   270 | D_loss: -0.05049 | G_loss: 0.00913\n",
      "Epoch:   275 | D_loss: -0.04916 | G_loss: -0.00900\n",
      "Epoch:   280 | D_loss: -0.05064 | G_loss: 0.01908\n",
      "Epoch:   285 | D_loss: -0.04850 | G_loss: 0.02732\n",
      "Epoch:   290 | D_loss: -0.05340 | G_loss: -0.00274\n",
      "Epoch:   295 | D_loss: -0.04975 | G_loss: -0.03411\n",
      "Epoch:   300 | D_loss: -0.06702 | G_loss: 0.07247\n",
      "Epoch:   305 | D_loss: -0.05358 | G_loss: 0.08315\n",
      "Epoch:   310 | D_loss: -0.04508 | G_loss: 0.05262\n",
      "Epoch:   315 | D_loss: -0.04599 | G_loss: 0.06093\n",
      "Epoch:   320 | D_loss: -0.04121 | G_loss: 0.00222\n",
      "Epoch:   325 | D_loss: -0.04367 | G_loss: 0.14947\n",
      "Epoch:   330 | D_loss: -0.04943 | G_loss: 0.06327\n",
      "Epoch:   335 | D_loss: -0.04159 | G_loss: 0.11230\n",
      "Epoch:   340 | D_loss: -0.03734 | G_loss: 0.13292\n",
      "Epoch:   345 | D_loss: -0.03571 | G_loss: 0.16507\n",
      "Epoch:   350 | D_loss: -0.04068 | G_loss: 0.05853\n",
      "Epoch:   355 | D_loss: -0.04499 | G_loss: 0.06988\n",
      "Epoch:   360 | D_loss: -0.03562 | G_loss: 0.12579\n",
      "Epoch:   365 | D_loss: -0.04638 | G_loss: -0.00256\n",
      "Epoch:   370 | D_loss: -0.04170 | G_loss: 0.15003\n",
      "Epoch:   375 | D_loss: -0.03978 | G_loss: 0.01105\n",
      "Epoch:   380 | D_loss: -0.03975 | G_loss: 0.05549\n",
      "Epoch:   385 | D_loss: -0.03544 | G_loss: 0.01710\n",
      "Epoch:   390 | D_loss: -0.04219 | G_loss: 0.15086\n",
      "Epoch:   395 | D_loss: -0.05352 | G_loss: 0.02193\n",
      "Epoch:   400 | D_loss: -0.03634 | G_loss: 0.06861\n",
      "Epoch:   405 | D_loss: -0.03505 | G_loss: 0.07549\n",
      "Epoch:   410 | D_loss: -0.04520 | G_loss: 0.08205\n",
      "Epoch:   415 | D_loss: -0.03504 | G_loss: 0.08485\n",
      "Epoch:   420 | D_loss: -0.04703 | G_loss: 0.01715\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m n_data \u001b[38;5;241m=\u001b[39m real_img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m## Real and Fake Images\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m real_img \u001b[38;5;241m=\u001b[39m \u001b[43mreal_img\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m fake_img \u001b[38;5;241m=\u001b[39m G\u001b[38;5;241m.\u001b[39mgenerate(n_data, device)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m## Real and Fake Labels\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_epochs = 1000\n",
    "for epoch in range(max_epochs):\n",
    "    D.train()\n",
    "    G.train()\n",
    "    for i, (real_img, _) in enumerate(trainloader):\n",
    "        n_data = real_img.shape[0]\n",
    "        ## Real and Fake Images\n",
    "        real_img = real_img.to(device)\n",
    "        fake_img = G.generate(n_data, device)\n",
    "\n",
    "        ## Real and Fake Labels\n",
    "        real = -torch.ones((n_data, 1), device=device)\n",
    "        fake = torch.ones((n_data, 1), device=device)\n",
    "\n",
    "        ## Training Discriminator ##\n",
    "        d_optimizer.zero_grad()\n",
    "        # Real image -> Discriminator -> label Real\n",
    "        output = D(real_img)\n",
    "        d_real_loss = criterion(output, real)\n",
    "        \n",
    "        # Fake image -> Discriminator -> label Fake\n",
    "        output = D(fake_img.detach())\n",
    "        d_fake_loss = criterion(output, fake)\n",
    "        \n",
    "        d_loss = d_real_loss + d_fake_loss\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        # Weight clipping\n",
    "        D.clip_weights()\n",
    "\n",
    "        if i % 5 == 0:\n",
    "            ## Training Generator ##\n",
    "            g_optimizer.zero_grad()\n",
    "            # Fake image -> Discriminator -> label Real\n",
    "            output = D(fake_img)\n",
    "            g_loss = criterion(output, real)        \n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"Epoch: {epoch:5} | D_loss: {d_loss/2:.5f} | G_loss: {g_loss:.5f}\")\n",
    "\n",
    "    if epoch % 15 == 0:\n",
    "        G.eval()\n",
    "        epoch = str(epoch).zfill(4)\n",
    "        fake_img = G.generate(64, device)\n",
    "        save_image(fake_img, f\"output/WDCGAN/{epoch}.jpg\", nrow=8, normalize=True)\n",
    "        \n",
    "        torch.save(D, \"model/WDCGAN/critic.pth\")\n",
    "        torch.save(G, \"model/WDCGAN/generator.pth\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Part 4 - Wasserstein DCGAN with PyTorch - CelebA Dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:MachineLearning] *",
   "language": "python",
   "name": "conda-env-MachineLearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
