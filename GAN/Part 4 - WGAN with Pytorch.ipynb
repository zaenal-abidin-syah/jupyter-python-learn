{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99aceace-5f30-411e-a25b-d29619dad728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gdown jcopdl\n",
    "# !gdown https://drive.google.com/uc?id=12DT5Px7FQV7gZEcygWvKb5aZQw2ZprSP\n",
    "# !unzip /content/mnist.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69730a24-9f43-4a92-9bbd-cec792b84bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from jcopdl.callback import Callback, set_config\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adee5fb0-3506-42ef-bc61-793ecaeb6b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75510a33-eb73-4048-a940-a619da33bf80",
   "metadata": {},
   "source": [
    "# Dataset dan Dataloader (hanya train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ca3b6fa-36b9-4675-83d0-b183a5fd25c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "459d2b8e-0ae1-4b2f-a360-2b8ed3ae89e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "train_set = datasets.ImageFolder(\"data/train\", transform=transform)\n",
    "trainloader = DataLoader(train_set, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4e7d6d-b007-4625-8eca-8670b04b4c43",
   "metadata": {},
   "source": [
    "# Arsitekstur dan Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb8dd1a-e69a-4739-94d0-7f1a9a8c24ad",
   "metadata": {},
   "source": [
    "### sumber [paper](https://arxiv.org/pdf/1701.07875.pdf)\n",
    "```python\n",
    "- diakhiri aktivasi Linear dan bukan Sigmoid<br>\n",
    "  `linear_block(128, 1, activation=None)`\n",
    "- diadopsi dari teori optimal transport, menggunakan wasserstein Loss<br>\n",
    "\n",
    "def wasserstein_loss(output, target):\n",
    "    return output.mean() * target.mean()\n",
    "        \n",
    "- Note : Fake = +1 | Real = -1\n",
    "- Momentum based Optimizer kadang membuat GAN tidak stabil\n",
    "- Menggunakan RMSProp, lr yang kecil (misalnya 5e-5) <br>\n",
    "\n",
    "  d_optimizer = optim.RMSprop(D.parameters(), lr=5e-5)\n",
    "  g_optimizer = optim.RMSprop(G.parameters(), lr=5e-5)\n",
    "  \n",
    "- Weight pada critic dibatasi misalnya [-0,01, 0,01] <br>\n",
    "\n",
    "  def clip_weights(self, vmin=-0.01, vmax=0.01):\n",
    "    for p in self.parameters():\n",
    "        p.data.clamp_(vmin, vmax)\n",
    "- train critic lebih banyak pada generator<br>\n",
    "  if n_batch % 5 ==0:\n",
    "      #train generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12ba5a0b-e577-439b-94a2-3368a220bbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jcopdl.layers import linear_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72cfe7b8-9033-4e04-85e6-f1742d4168ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_wgan.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_wgan.py\n",
    "import torch\n",
    "from torch import nn\n",
    "from jcopdl.layers import linear_block\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            linear_block(784, 512, activation='lrelu'),\n",
    "            linear_block(512, 256, activation='lrelu'),\n",
    "            linear_block(256, 128, activation='lrelu'),\n",
    "            # linear_block(128, 1, activation=None)\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "    def clip_weights(self, vmin=-0.01, vmax=0.01):\n",
    "        for p in self.parameters():\n",
    "            p.data.clamp_(vmin, vmax)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        super().__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.fc = nn.Sequential(\n",
    "            linear_block(self.z_dim, 128, activation='lrelu'),\n",
    "            linear_block(128, 256, activation='lrelu', batch_norm=True),\n",
    "            linear_block(256, 512, activation='lrelu', batch_norm=True),\n",
    "            linear_block(512, 1024, activation='lrelu', batch_norm=True),\n",
    "            linear_block(1024, 784, activation='tanh')\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "    def generate(self, n, device):\n",
    "        z = torch.randn((n, self.z_dim), device=device)\n",
    "        return self.fc(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8471e88-847a-4cc7-9c0f-7c844a16905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = set_config({\n",
    "    'z_dim': 100,\n",
    "    'batch_size':bs\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211a2a05-f336-4e85-b025-8e845c47531b",
   "metadata": {},
   "source": [
    "# training Preparation -> MCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afa24978-ef40-41fc-b775-ccab67777cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_wgan import Critic, Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7b4aaf7-5316-48a7-ba80-7b13e898a9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss(output, target):\n",
    "    return output.mean() * target.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69887f29-ef9f-40e2-bbc3-43fc31d9fc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Critic().to(device)\n",
    "G = Generator(config.z_dim).to(device)\n",
    "\n",
    "criterion = wasserstein_loss\n",
    "# criterion = nn.BCELoss()\n",
    "# d_optimizer = optim.Adam(D.parameters(), lr=0.0002)\n",
    "# g_optimizer = optim.Adam(G.parameters(), lr=0.0002)\n",
    "d_optimizer = optim.RMSprop(D.parameters(), lr=5e-5)\n",
    "g_optimizer = optim.RMSprop(G.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4742720-8711-42a6-a29b-44b2f5280f7e",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63535eec-7796-4f07-93a3-a302c36dc61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision.utils import save_image\n",
    "os.makedirs(\"output/WGAN/\", exist_ok=True)\n",
    "os.makedirs(\"model/WGAN/\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "034dda6c-3fce-4f2c-8e24-6f2815260bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     0 : | D_loss : -0.017161 | G_loss : -0.020237\n",
      "Epoch     5 : | D_loss : -0.031785 | G_loss : -1.105294\n",
      "Epoch    10 : | D_loss : -0.057694 | G_loss : -1.850849\n",
      "Epoch    15 : | D_loss : -0.062357 | G_loss : -1.666635\n",
      "Epoch    20 : | D_loss : -0.054528 | G_loss : -1.344638\n",
      "Epoch    25 : | D_loss : -0.067599 | G_loss : -1.021007\n",
      "Epoch    30 : | D_loss : -0.086399 | G_loss : -0.571073\n",
      "Epoch    35 : | D_loss : -0.035489 | G_loss : -0.541371\n",
      "Epoch    40 : | D_loss : -0.057620 | G_loss : -0.384826\n",
      "Epoch    45 : | D_loss : -0.039812 | G_loss : -0.433597\n",
      "Epoch    50 : | D_loss : -0.063830 | G_loss : -0.179912\n",
      "Epoch    55 : | D_loss : -0.078385 | G_loss : -0.031712\n",
      "Epoch    60 : | D_loss : -0.085959 | G_loss : 0.373750\n",
      "Epoch    65 : | D_loss : -0.049251 | G_loss : -0.251536\n",
      "Epoch    70 : | D_loss : -0.062182 | G_loss : -0.497509\n",
      "Epoch    75 : | D_loss : -0.081720 | G_loss : -0.768480\n",
      "Epoch    80 : | D_loss : -0.075976 | G_loss : -0.708248\n",
      "Epoch    85 : | D_loss : -0.107046 | G_loss : -0.478739\n",
      "Epoch    90 : | D_loss : -0.060142 | G_loss : -0.585859\n",
      "Epoch    95 : | D_loss : -0.059466 | G_loss : -0.839072\n",
      "Epoch   100 : | D_loss : -0.061168 | G_loss : -0.083117\n",
      "Epoch   105 : | D_loss : -0.070272 | G_loss : -0.484656\n",
      "Epoch   110 : | D_loss : -0.089900 | G_loss : -0.217370\n",
      "Epoch   115 : | D_loss : -0.049822 | G_loss : -0.418737\n",
      "Epoch   120 : | D_loss : -0.077667 | G_loss : -0.460977\n",
      "Epoch   125 : | D_loss : -0.065121 | G_loss : -0.055080\n",
      "Epoch   130 : | D_loss : -0.094088 | G_loss : 0.277698\n",
      "Epoch   135 : | D_loss : -0.057084 | G_loss : -0.114256\n",
      "Epoch   140 : | D_loss : -0.062835 | G_loss : -0.418190\n",
      "Epoch   145 : | D_loss : -0.062329 | G_loss : 0.041314\n",
      "Epoch   150 : | D_loss : -0.058481 | G_loss : -0.200308\n",
      "Epoch   155 : | D_loss : -0.053331 | G_loss : -0.324046\n",
      "Epoch   160 : | D_loss : -0.063189 | G_loss : -0.800378\n",
      "Epoch   165 : | D_loss : -0.058793 | G_loss : -0.649787\n",
      "Epoch   170 : | D_loss : -0.078605 | G_loss : -0.568783\n",
      "Epoch   175 : | D_loss : -0.062289 | G_loss : -0.443598\n",
      "Epoch   180 : | D_loss : -0.056524 | G_loss : -0.570414\n",
      "Epoch   185 : | D_loss : -0.064353 | G_loss : -0.698350\n",
      "Epoch   190 : | D_loss : -0.073054 | G_loss : -0.625137\n",
      "Epoch   195 : | D_loss : -0.074830 | G_loss : -0.759511\n",
      "Epoch   200 : | D_loss : -0.043374 | G_loss : -0.093119\n",
      "Epoch   205 : | D_loss : -0.060139 | G_loss : -0.911541\n",
      "Epoch   210 : | D_loss : -0.056027 | G_loss : -0.426431\n",
      "Epoch   215 : | D_loss : -0.078469 | G_loss : -0.423428\n",
      "Epoch   220 : | D_loss : -0.051949 | G_loss : -0.470081\n",
      "Epoch   225 : | D_loss : -0.055096 | G_loss : -0.478619\n",
      "Epoch   230 : | D_loss : -0.053320 | G_loss : -0.771413\n",
      "Epoch   235 : | D_loss : -0.044019 | G_loss : -0.583889\n",
      "Epoch   240 : | D_loss : -0.058743 | G_loss : -0.753390\n",
      "Epoch   245 : | D_loss : -0.056249 | G_loss : -0.511989\n",
      "Epoch   250 : | D_loss : -0.059387 | G_loss : 0.188304\n",
      "Epoch   255 : | D_loss : -0.043122 | G_loss : 0.041653\n",
      "Epoch   260 : | D_loss : -0.053403 | G_loss : -0.545992\n",
      "Epoch   265 : | D_loss : -0.060753 | G_loss : -0.619990\n",
      "Epoch   270 : | D_loss : -0.050155 | G_loss : -0.622396\n",
      "Epoch   275 : | D_loss : -0.048118 | G_loss : -0.222469\n",
      "Epoch   280 : | D_loss : -0.044062 | G_loss : -0.884548\n",
      "Epoch   285 : | D_loss : -0.029036 | G_loss : -0.275080\n",
      "Epoch   290 : | D_loss : -0.042674 | G_loss : -1.116187\n",
      "Epoch   295 : | D_loss : -0.035854 | G_loss : -0.333649\n",
      "Epoch   300 : | D_loss : -0.033871 | G_loss : -0.185524\n",
      "Epoch   305 : | D_loss : -0.040890 | G_loss : -1.010770\n",
      "Epoch   310 : | D_loss : -0.026713 | G_loss : 0.023202\n",
      "Epoch   315 : | D_loss : -0.048007 | G_loss : 0.323111\n",
      "Epoch   320 : | D_loss : -0.037244 | G_loss : -0.144746\n",
      "Epoch   325 : | D_loss : -0.039967 | G_loss : -0.506157\n",
      "Epoch   330 : | D_loss : -0.056906 | G_loss : -0.491190\n",
      "Epoch   335 : | D_loss : -0.036065 | G_loss : -0.549278\n",
      "Epoch   340 : | D_loss : -0.042848 | G_loss : -0.649873\n",
      "Epoch   345 : | D_loss : -0.037516 | G_loss : -0.036195\n",
      "Epoch   350 : | D_loss : -0.035358 | G_loss : -0.478249\n",
      "Epoch   355 : | D_loss : -0.048629 | G_loss : -0.977232\n",
      "Epoch   360 : | D_loss : -0.036150 | G_loss : -0.684789\n",
      "Epoch   365 : | D_loss : -0.048296 | G_loss : -0.337676\n",
      "Epoch   370 : | D_loss : -0.039062 | G_loss : -0.598137\n",
      "Epoch   375 : | D_loss : -0.042109 | G_loss : -0.565593\n",
      "Epoch   380 : | D_loss : -0.035218 | G_loss : -0.414686\n",
      "Epoch   385 : | D_loss : -0.042184 | G_loss : -0.203764\n",
      "Epoch   390 : | D_loss : -0.046773 | G_loss : 0.738500\n",
      "Epoch   395 : | D_loss : -0.028794 | G_loss : -0.458803\n",
      "Epoch   400 : | D_loss : -0.038184 | G_loss : -0.782960\n",
      "Epoch   405 : | D_loss : -0.033679 | G_loss : -0.720990\n",
      "Epoch   410 : | D_loss : -0.034601 | G_loss : -0.032176\n",
      "Epoch   415 : | D_loss : -0.034305 | G_loss : 0.157775\n",
      "Epoch   420 : | D_loss : -0.028724 | G_loss : -0.732499\n",
      "Epoch   425 : | D_loss : -0.026879 | G_loss : 0.077826\n",
      "Epoch   430 : | D_loss : -0.028649 | G_loss : -0.787446\n",
      "Epoch   435 : | D_loss : -0.045727 | G_loss : -0.770152\n",
      "Epoch   440 : | D_loss : -0.034382 | G_loss : -0.553555\n",
      "Epoch   445 : | D_loss : -0.017412 | G_loss : 0.580138\n",
      "Epoch   450 : | D_loss : -0.031001 | G_loss : 0.022529\n",
      "Epoch   455 : | D_loss : -0.022774 | G_loss : 0.218971\n",
      "Epoch   460 : | D_loss : -0.032518 | G_loss : -0.445911\n",
      "Epoch   465 : | D_loss : -0.036127 | G_loss : -0.823557\n",
      "Epoch   470 : | D_loss : -0.023933 | G_loss : -0.579993\n",
      "Epoch   475 : | D_loss : -0.022513 | G_loss : 0.297428\n",
      "Epoch   480 : | D_loss : -0.030924 | G_loss : -0.360589\n",
      "Epoch   485 : | D_loss : -0.041607 | G_loss : -0.296615\n",
      "Epoch   490 : | D_loss : -0.025229 | G_loss : -0.876856\n",
      "Epoch   495 : | D_loss : -0.036716 | G_loss : -0.368627\n",
      "Epoch   500 : | D_loss : -0.035352 | G_loss : -1.030406\n",
      "Epoch   505 : | D_loss : -0.035155 | G_loss : -0.810425\n",
      "Epoch   510 : | D_loss : -0.040758 | G_loss : 0.344321\n",
      "Epoch   515 : | D_loss : -0.021791 | G_loss : -0.227200\n",
      "Epoch   520 : | D_loss : -0.038250 | G_loss : 0.089901\n",
      "Epoch   525 : | D_loss : -0.024548 | G_loss : -0.188854\n",
      "Epoch   530 : | D_loss : -0.031556 | G_loss : -0.254024\n",
      "Epoch   535 : | D_loss : -0.032257 | G_loss : -0.437183\n",
      "Epoch   540 : | D_loss : -0.031614 | G_loss : -0.155647\n",
      "Epoch   545 : | D_loss : -0.036900 | G_loss : 0.298127\n",
      "Epoch   550 : | D_loss : -0.036607 | G_loss : -0.256259\n",
      "Epoch   555 : | D_loss : -0.030578 | G_loss : -0.878666\n",
      "Epoch   560 : | D_loss : -0.030561 | G_loss : 0.809110\n",
      "Epoch   565 : | D_loss : -0.022514 | G_loss : -0.317722\n",
      "Epoch   570 : | D_loss : -0.028786 | G_loss : -0.420788\n",
      "Epoch   575 : | D_loss : -0.033227 | G_loss : -0.523589\n",
      "Epoch   580 : | D_loss : -0.023096 | G_loss : -0.824682\n",
      "Epoch   585 : | D_loss : -0.028650 | G_loss : -0.249322\n",
      "Epoch   590 : | D_loss : -0.027054 | G_loss : -0.384108\n",
      "Epoch   595 : | D_loss : -0.031012 | G_loss : -0.182780\n",
      "Epoch   600 : | D_loss : -0.020079 | G_loss : -0.935533\n",
      "Epoch   605 : | D_loss : -0.023991 | G_loss : -0.743058\n",
      "Epoch   610 : | D_loss : -0.030916 | G_loss : -0.318654\n",
      "Epoch   615 : | D_loss : -0.025798 | G_loss : -0.908671\n",
      "Epoch   620 : | D_loss : -0.013916 | G_loss : -0.269444\n",
      "Epoch   625 : | D_loss : -0.024685 | G_loss : -0.764545\n",
      "Epoch   630 : | D_loss : -0.030114 | G_loss : -0.955007\n",
      "Epoch   635 : | D_loss : -0.022191 | G_loss : -1.007024\n",
      "Epoch   640 : | D_loss : -0.027283 | G_loss : -0.050945\n",
      "Epoch   645 : | D_loss : -0.032232 | G_loss : -0.412931\n",
      "Epoch   650 : | D_loss : -0.020716 | G_loss : 0.084410\n",
      "Epoch   655 : | D_loss : -0.024698 | G_loss : -0.862385\n",
      "Epoch   660 : | D_loss : -0.021202 | G_loss : -0.443128\n",
      "Epoch   665 : | D_loss : -0.019138 | G_loss : -1.054605\n",
      "Epoch   670 : | D_loss : -0.031835 | G_loss : -0.567111\n",
      "Epoch   675 : | D_loss : -0.024196 | G_loss : -0.592759\n",
      "Epoch   680 : | D_loss : -0.021076 | G_loss : 0.082649\n",
      "Epoch   685 : | D_loss : -0.027195 | G_loss : -0.093923\n",
      "Epoch   690 : | D_loss : -0.026720 | G_loss : -0.486830\n",
      "Epoch   695 : | D_loss : -0.027652 | G_loss : -0.749731\n",
      "Epoch   700 : | D_loss : -0.023127 | G_loss : -0.541449\n",
      "Epoch   705 : | D_loss : -0.014599 | G_loss : 0.793767\n",
      "Epoch   710 : | D_loss : -0.016827 | G_loss : -0.136973\n",
      "Epoch   715 : | D_loss : -0.030799 | G_loss : -0.714431\n",
      "Epoch   720 : | D_loss : -0.019792 | G_loss : -0.340379\n",
      "Epoch   725 : | D_loss : -0.017400 | G_loss : -0.244025\n",
      "Epoch   730 : | D_loss : -0.022865 | G_loss : -1.050104\n",
      "Epoch   735 : | D_loss : -0.019541 | G_loss : -0.634788\n",
      "Epoch   740 : | D_loss : -0.027351 | G_loss : -0.026019\n",
      "Epoch   745 : | D_loss : -0.010943 | G_loss : -1.073183\n",
      "Epoch   750 : | D_loss : -0.021749 | G_loss : -0.997477\n",
      "Epoch   755 : | D_loss : -0.032302 | G_loss : 0.040557\n",
      "Epoch   760 : | D_loss : -0.021328 | G_loss : -0.372706\n",
      "Epoch   765 : | D_loss : -0.022815 | G_loss : -0.531021\n",
      "Epoch   770 : | D_loss : -0.021973 | G_loss : -0.367633\n",
      "Epoch   775 : | D_loss : -0.022408 | G_loss : 0.545844\n",
      "Epoch   780 : | D_loss : -0.022801 | G_loss : -0.157705\n",
      "Epoch   785 : | D_loss : -0.022140 | G_loss : -0.370326\n",
      "Epoch   790 : | D_loss : -0.030576 | G_loss : -0.101027\n",
      "Epoch   795 : | D_loss : -0.021194 | G_loss : -0.999290\n",
      "Epoch   800 : | D_loss : -0.016635 | G_loss : -0.900877\n",
      "Epoch   805 : | D_loss : -0.026218 | G_loss : 0.249624\n",
      "Epoch   810 : | D_loss : -0.020869 | G_loss : -0.071608\n",
      "Epoch   815 : | D_loss : -0.011802 | G_loss : -0.454377\n",
      "Epoch   820 : | D_loss : -0.020201 | G_loss : -0.749644\n",
      "Epoch   825 : | D_loss : -0.022848 | G_loss : 0.339980\n",
      "Epoch   830 : | D_loss : -0.016749 | G_loss : -0.860956\n",
      "Epoch   835 : | D_loss : -0.017799 | G_loss : 0.019606\n",
      "Epoch   840 : | D_loss : -0.032092 | G_loss : 0.496864\n",
      "Epoch   845 : | D_loss : -0.016374 | G_loss : -0.124530\n",
      "Epoch   850 : | D_loss : -0.016129 | G_loss : -0.800521\n",
      "Epoch   855 : | D_loss : -0.019281 | G_loss : -0.242610\n",
      "Epoch   860 : | D_loss : -0.009700 | G_loss : -0.965668\n",
      "Epoch   865 : | D_loss : -0.015768 | G_loss : -0.162148\n",
      "Epoch   870 : | D_loss : -0.023091 | G_loss : -0.315474\n",
      "Epoch   875 : | D_loss : -0.017525 | G_loss : -0.802061\n",
      "Epoch   880 : | D_loss : -0.016380 | G_loss : -0.502708\n",
      "Epoch   885 : | D_loss : -0.022215 | G_loss : -0.820869\n",
      "Epoch   890 : | D_loss : -0.021083 | G_loss : -0.350402\n",
      "Epoch   895 : | D_loss : -0.017833 | G_loss : -0.537063\n",
      "Epoch   900 : | D_loss : -0.021299 | G_loss : -0.316200\n",
      "Epoch   905 : | D_loss : -0.019404 | G_loss : -1.081458\n",
      "Epoch   910 : | D_loss : -0.022688 | G_loss : -0.484641\n",
      "Epoch   915 : | D_loss : -0.020635 | G_loss : -0.526629\n",
      "Epoch   920 : | D_loss : -0.020610 | G_loss : 0.230963\n",
      "Epoch   925 : | D_loss : -0.023737 | G_loss : -0.340695\n",
      "Epoch   930 : | D_loss : -0.015152 | G_loss : -0.888175\n",
      "Epoch   935 : | D_loss : -0.013135 | G_loss : -0.454849\n",
      "Epoch   940 : | D_loss : -0.021451 | G_loss : -0.863787\n",
      "Epoch   945 : | D_loss : -0.015270 | G_loss : -0.351442\n",
      "Epoch   950 : | D_loss : -0.012641 | G_loss : -0.859356\n",
      "Epoch   955 : | D_loss : -0.006167 | G_loss : -1.013150\n",
      "Epoch   960 : | D_loss : -0.015433 | G_loss : -0.272710\n",
      "Epoch   965 : | D_loss : -0.021175 | G_loss : 0.324173\n",
      "Epoch   970 : | D_loss : -0.027291 | G_loss : 0.376525\n",
      "Epoch   975 : | D_loss : -0.013365 | G_loss : -1.207586\n",
      "Epoch   980 : | D_loss : -0.016081 | G_loss : -0.312001\n",
      "Epoch   985 : | D_loss : -0.020941 | G_loss : -0.362845\n",
      "Epoch   990 : | D_loss : -0.019385 | G_loss : -0.609265\n",
      "Epoch   995 : | D_loss : -0.013634 | G_loss : -0.457119\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 1000\n",
    "for epoch in range(max_epochs):\n",
    "    D.train()\n",
    "    G.train()\n",
    "    for i, (real_img, _) in enumerate(trainloader):\n",
    "        n_data = real_img.shape[0]\n",
    "\n",
    "        # Real dan Fake Images\n",
    "        real_img = real_img.to(device)\n",
    "        fake_image = G.generate(n_data, device)\n",
    "        # Real dan Fake Labels\n",
    "        real = - torch.ones((n_data, 1), device=device)\n",
    "        fake = torch.ones((n_data, 1), device=device)\n",
    "        # Training Discriminator\n",
    "        d_optimizer.zero_grad()\n",
    "        ## Real Image -> Discriminator -> Label Real\n",
    "        output = D(real_img)\n",
    "        d_real_loss = criterion(output, real)\n",
    "        ## Fake Image -> Discriminator -> Label Fake\n",
    "        output = D(fake_image.detach())\n",
    "        d_fake_loss = criterion(output, fake)\n",
    "\n",
    "        d_loss = d_real_loss + d_fake_loss\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        D.clip_weights()\n",
    "        if i % 5 == 0:\n",
    "            # Training Generator\n",
    "            g_optimizer.zero_grad()\n",
    "            ## Fake Image -> Discriminator -> tapi Label Real\n",
    "            output = D(fake_image)\n",
    "            g_loss = criterion(output, real)\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "        \n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"Epoch {epoch:5} : | D_loss : {d_loss/2:5f} | G_loss : {g_loss:5f}\")\n",
    "    if epoch % 15 == 0:\n",
    "        G.eval()\n",
    "        epoch = str(epoch).zfill(4)\n",
    "        fake_image = G.generate(64, device=device)\n",
    "        save_image(fake_image.view(-1, 1, 28, 28), f\"output/WGAN/{epoch}.jpg\", nrow=8, normalize=True)\n",
    "\n",
    "        torch.save(D, \"model/WGAN/discriminator.pth\")\n",
    "        torch.save(G, \"model/WGAN/generator.pth\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee6771f-e71e-4edf-86f1-d0301bd4bf15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8777a3e-8148-4f3c-905f-6f06b3a988c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MachineLearning] *",
   "language": "python",
   "name": "conda-env-MachineLearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
