{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99aceace-5f30-411e-a25b-d29619dad728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gdown jcopdl\n",
    "# !gdown https://drive.google.com/uc?id=12DT5Px7FQV7gZEcygWvKb5aZQw2ZprSP\n",
    "# !unzip /content/mnist.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69730a24-9f43-4a92-9bbd-cec792b84bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from jcopdl.callback import Callback, set_config\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adee5fb0-3506-42ef-bc61-793ecaeb6b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75510a33-eb73-4048-a940-a619da33bf80",
   "metadata": {},
   "source": [
    "# Dataset dan Dataloader (hanya train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ca3b6fa-36b9-4675-83d0-b183a5fd25c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "459d2b8e-0ae1-4b2f-a360-2b8ed3ae89e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "train_set = datasets.ImageFolder(\"data/train\", transform=transform)\n",
    "trainloader = DataLoader(train_set, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72cfe7b8-9033-4e04-85e6-f1742d4168ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_gan.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_gan.py\n",
    "import torch\n",
    "from torch import nn\n",
    "from jcopdl.layers import linear_block\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            linear_block(784, 512, activation='lrelu'),\n",
    "            linear_block(512, 256, activation='lrelu'),\n",
    "            linear_block(256, 128, activation='lrelu'),\n",
    "            linear_block(128, 1, activation='sigmoid'),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        super().__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.fc = nn.Sequential(\n",
    "            linear_block(self.z_dim, 128, activation='lrelu'),\n",
    "            linear_block(128, 256, activation='lrelu', batch_norm=True),\n",
    "            linear_block(256, 512, activation='lrelu', batch_norm=True),\n",
    "            linear_block(512, 1024, activation='lrelu', batch_norm=True),\n",
    "            linear_block(1024, 784, activation='tanh')\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "    def generate(self, n, device):\n",
    "        z = torch.randn((n, self.z_dim), device=device)\n",
    "        return self.fc(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8471e88-847a-4cc7-9c0f-7c844a16905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = set_config({\n",
    "    'z_dim': 100,\n",
    "    'batch_size':bs\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211a2a05-f336-4e85-b025-8e845c47531b",
   "metadata": {},
   "source": [
    "# training Preparation -> MCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afa24978-ef40-41fc-b775-ccab67777cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_gan import Discriminator, Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69887f29-ef9f-40e2-bbc3-43fc31d9fc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator().to(device)\n",
    "G = Generator(config.z_dim).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "d_optimizer = optim.Adam(D.parameters(), lr=0.0002)\n",
    "g_optimizer = optim.Adam(G.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4742720-8711-42a6-a29b-44b2f5280f7e",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63535eec-7796-4f07-93a3-a302c36dc61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision.utils import save_image\n",
    "os.makedirs(\"output/GAN/\", exist_ok=True)\n",
    "os.makedirs(\"model/GAN/\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "034dda6c-3fce-4f2c-8e24-6f2815260bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     0 : | D_loss : 0.620034 | G_loss : 0.893318\n",
      "Epoch     5 : | D_loss : 0.029480 | G_loss : 15.326870\n",
      "Epoch    10 : | D_loss : 0.000914 | G_loss : 10.692772\n",
      "Epoch    15 : | D_loss : 0.230609 | G_loss : 11.841581\n",
      "Epoch    20 : | D_loss : 0.020662 | G_loss : 11.104354\n",
      "Epoch    25 : | D_loss : 0.115729 | G_loss : 9.415239\n",
      "Epoch    30 : | D_loss : 0.335380 | G_loss : 9.909477\n",
      "Epoch    35 : | D_loss : 0.063014 | G_loss : 5.366125\n",
      "Epoch    40 : | D_loss : 0.136325 | G_loss : 4.241593\n",
      "Epoch    45 : | D_loss : 0.245341 | G_loss : 4.268900\n",
      "Epoch    50 : | D_loss : 0.272129 | G_loss : 4.680780\n",
      "Epoch    55 : | D_loss : 0.258448 | G_loss : 3.385092\n",
      "Epoch    60 : | D_loss : 0.226616 | G_loss : 3.432909\n",
      "Epoch    65 : | D_loss : 0.160086 | G_loss : 4.082263\n",
      "Epoch    70 : | D_loss : 0.360658 | G_loss : 4.361314\n",
      "Epoch    75 : | D_loss : 0.234619 | G_loss : 3.316228\n",
      "Epoch    80 : | D_loss : 0.426729 | G_loss : 2.225915\n",
      "Epoch    85 : | D_loss : 0.071605 | G_loss : 5.672840\n",
      "Epoch    90 : | D_loss : 0.277529 | G_loss : 4.243258\n",
      "Epoch    95 : | D_loss : 0.306423 | G_loss : 4.768930\n",
      "Epoch   100 : | D_loss : 0.254040 | G_loss : 6.258201\n",
      "Epoch   105 : | D_loss : 0.232744 | G_loss : 4.251410\n",
      "Epoch   110 : | D_loss : 0.090292 | G_loss : 5.439679\n",
      "Epoch   115 : | D_loss : 0.182728 | G_loss : 3.568414\n",
      "Epoch   120 : | D_loss : 0.266626 | G_loss : 3.628244\n",
      "Epoch   125 : | D_loss : 0.323241 | G_loss : 4.776829\n",
      "Epoch   130 : | D_loss : 0.041884 | G_loss : 6.007412\n",
      "Epoch   135 : | D_loss : 0.407976 | G_loss : 5.511402\n",
      "Epoch   140 : | D_loss : 0.109378 | G_loss : 4.124331\n",
      "Epoch   145 : | D_loss : 0.281671 | G_loss : 2.280858\n",
      "Epoch   150 : | D_loss : 0.497881 | G_loss : 1.683429\n",
      "Epoch   155 : | D_loss : 0.223612 | G_loss : 1.808341\n",
      "Epoch   160 : | D_loss : 0.485564 | G_loss : 2.237420\n",
      "Epoch   165 : | D_loss : 0.319359 | G_loss : 3.389440\n",
      "Epoch   170 : | D_loss : 0.151908 | G_loss : 4.235021\n",
      "Epoch   175 : | D_loss : 0.337383 | G_loss : 2.246525\n",
      "Epoch   180 : | D_loss : 0.412754 | G_loss : 2.513165\n",
      "Epoch   185 : | D_loss : 0.228119 | G_loss : 4.411598\n",
      "Epoch   190 : | D_loss : 0.119485 | G_loss : 2.920996\n",
      "Epoch   195 : | D_loss : 0.455167 | G_loss : 1.892339\n",
      "Epoch   200 : | D_loss : 0.352307 | G_loss : 7.162270\n",
      "Epoch   205 : | D_loss : 0.242961 | G_loss : 3.320971\n",
      "Epoch   210 : | D_loss : 0.401398 | G_loss : 2.381318\n",
      "Epoch   215 : | D_loss : 0.241791 | G_loss : 5.833779\n",
      "Epoch   220 : | D_loss : 0.361370 | G_loss : 2.262151\n",
      "Epoch   225 : | D_loss : 0.410868 | G_loss : 2.578412\n",
      "Epoch   230 : | D_loss : 0.380111 | G_loss : 2.733151\n",
      "Epoch   235 : | D_loss : 0.564313 | G_loss : 1.702642\n",
      "Epoch   240 : | D_loss : 0.285606 | G_loss : 2.034362\n",
      "Epoch   245 : | D_loss : 0.488235 | G_loss : 1.743263\n",
      "Epoch   250 : | D_loss : 0.383176 | G_loss : 3.428687\n",
      "Epoch   255 : | D_loss : 0.229118 | G_loss : 3.180533\n",
      "Epoch   260 : | D_loss : 0.250686 | G_loss : 2.943794\n",
      "Epoch   265 : | D_loss : 0.224154 | G_loss : 2.366752\n",
      "Epoch   270 : | D_loss : 0.205096 | G_loss : 2.778672\n",
      "Epoch   275 : | D_loss : 0.750063 | G_loss : 3.610199\n",
      "Epoch   280 : | D_loss : 0.378157 | G_loss : 2.287325\n",
      "Epoch   285 : | D_loss : 0.262831 | G_loss : 1.920962\n",
      "Epoch   290 : | D_loss : 0.560983 | G_loss : 1.964082\n",
      "Epoch   295 : | D_loss : 0.316090 | G_loss : 2.087719\n",
      "Epoch   300 : | D_loss : 0.331667 | G_loss : 2.864727\n",
      "Epoch   305 : | D_loss : 0.180834 | G_loss : 3.118417\n",
      "Epoch   310 : | D_loss : 0.242914 | G_loss : 2.504615\n",
      "Epoch   315 : | D_loss : 0.300578 | G_loss : 2.830953\n",
      "Epoch   320 : | D_loss : 0.255312 | G_loss : 2.117929\n",
      "Epoch   325 : | D_loss : 0.480224 | G_loss : 2.313788\n",
      "Epoch   330 : | D_loss : 0.256897 | G_loss : 2.949207\n",
      "Epoch   335 : | D_loss : 0.296946 | G_loss : 3.612139\n",
      "Epoch   340 : | D_loss : 0.461916 | G_loss : 2.125257\n",
      "Epoch   345 : | D_loss : 0.344645 | G_loss : 2.433813\n",
      "Epoch   350 : | D_loss : 0.329944 | G_loss : 1.953046\n",
      "Epoch   355 : | D_loss : 0.417268 | G_loss : 2.204519\n",
      "Epoch   360 : | D_loss : 0.508268 | G_loss : 1.710590\n",
      "Epoch   365 : | D_loss : 0.481356 | G_loss : 1.604802\n",
      "Epoch   370 : | D_loss : 0.332277 | G_loss : 2.262118\n",
      "Epoch   375 : | D_loss : 0.518415 | G_loss : 1.474135\n",
      "Epoch   380 : | D_loss : 0.342671 | G_loss : 2.245071\n",
      "Epoch   385 : | D_loss : 0.488867 | G_loss : 2.544137\n",
      "Epoch   390 : | D_loss : 0.456957 | G_loss : 2.491444\n",
      "Epoch   395 : | D_loss : 0.343605 | G_loss : 2.616233\n",
      "Epoch   400 : | D_loss : 0.554916 | G_loss : 2.328016\n",
      "Epoch   405 : | D_loss : 0.543535 | G_loss : 2.214998\n",
      "Epoch   410 : | D_loss : 0.261252 | G_loss : 1.922199\n",
      "Epoch   415 : | D_loss : 0.419033 | G_loss : 2.002824\n",
      "Epoch   420 : | D_loss : 0.260641 | G_loss : 3.064182\n",
      "Epoch   425 : | D_loss : 0.690424 | G_loss : 2.162571\n",
      "Epoch   430 : | D_loss : 0.424053 | G_loss : 1.778779\n",
      "Epoch   435 : | D_loss : 0.171724 | G_loss : 4.619320\n",
      "Epoch   440 : | D_loss : 0.259698 | G_loss : 2.124577\n",
      "Epoch   445 : | D_loss : 0.432058 | G_loss : 1.416719\n",
      "Epoch   450 : | D_loss : 0.396591 | G_loss : 2.590634\n",
      "Epoch   455 : | D_loss : 0.435519 | G_loss : 1.647924\n",
      "Epoch   460 : | D_loss : 0.699546 | G_loss : 2.454092\n",
      "Epoch   465 : | D_loss : 0.264513 | G_loss : 2.164837\n",
      "Epoch   470 : | D_loss : 0.327618 | G_loss : 1.955359\n",
      "Epoch   475 : | D_loss : 0.339839 | G_loss : 2.413961\n",
      "Epoch   480 : | D_loss : 0.196423 | G_loss : 2.947453\n",
      "Epoch   485 : | D_loss : 0.273978 | G_loss : 2.101386\n",
      "Epoch   490 : | D_loss : 0.380941 | G_loss : 2.046885\n",
      "Epoch   495 : | D_loss : 0.410850 | G_loss : 1.961647\n",
      "Epoch   500 : | D_loss : 0.456092 | G_loss : 2.740554\n",
      "Epoch   505 : | D_loss : 0.490276 | G_loss : 1.448782\n",
      "Epoch   510 : | D_loss : 0.416409 | G_loss : 2.559204\n",
      "Epoch   515 : | D_loss : 0.195652 | G_loss : 2.414335\n",
      "Epoch   520 : | D_loss : 0.445033 | G_loss : 1.963813\n",
      "Epoch   525 : | D_loss : 0.262801 | G_loss : 2.683806\n",
      "Epoch   530 : | D_loss : 0.351704 | G_loss : 2.419667\n",
      "Epoch   535 : | D_loss : 0.349089 | G_loss : 1.789134\n",
      "Epoch   540 : | D_loss : 0.582680 | G_loss : 2.516802\n",
      "Epoch   545 : | D_loss : 0.616151 | G_loss : 1.865344\n",
      "Epoch   550 : | D_loss : 0.454327 | G_loss : 1.590800\n",
      "Epoch   555 : | D_loss : 0.258692 | G_loss : 4.029821\n",
      "Epoch   560 : | D_loss : 0.280910 | G_loss : 1.859731\n",
      "Epoch   565 : | D_loss : 0.445430 | G_loss : 2.311510\n",
      "Epoch   570 : | D_loss : 0.513264 | G_loss : 1.430806\n",
      "Epoch   575 : | D_loss : 0.317649 | G_loss : 2.548802\n",
      "Epoch   580 : | D_loss : 0.360362 | G_loss : 1.486203\n",
      "Epoch   585 : | D_loss : 0.732286 | G_loss : 1.959614\n",
      "Epoch   590 : | D_loss : 0.312301 | G_loss : 2.152435\n",
      "Epoch   595 : | D_loss : 0.221450 | G_loss : 3.450544\n",
      "Epoch   600 : | D_loss : 0.458707 | G_loss : 3.659606\n",
      "Epoch   605 : | D_loss : 0.486964 | G_loss : 2.644594\n",
      "Epoch   610 : | D_loss : 0.236092 | G_loss : 2.524762\n",
      "Epoch   615 : | D_loss : 0.459144 | G_loss : 1.816106\n",
      "Epoch   620 : | D_loss : 0.472688 | G_loss : 1.781353\n",
      "Epoch   625 : | D_loss : 0.509652 | G_loss : 1.452511\n",
      "Epoch   630 : | D_loss : 0.420691 | G_loss : 1.771847\n",
      "Epoch   635 : | D_loss : 0.384080 | G_loss : 2.143764\n",
      "Epoch   640 : | D_loss : 0.389816 | G_loss : 1.385606\n",
      "Epoch   645 : | D_loss : 0.473076 | G_loss : 1.775131\n",
      "Epoch   650 : | D_loss : 0.548997 | G_loss : 1.548741\n",
      "Epoch   655 : | D_loss : 0.570107 | G_loss : 2.008909\n",
      "Epoch   660 : | D_loss : 0.411349 | G_loss : 1.836804\n",
      "Epoch   665 : | D_loss : 0.312149 | G_loss : 3.087334\n",
      "Epoch   670 : | D_loss : 0.336320 | G_loss : 2.513583\n",
      "Epoch   675 : | D_loss : 0.340941 | G_loss : 1.818490\n",
      "Epoch   680 : | D_loss : 0.768690 | G_loss : 1.961774\n",
      "Epoch   685 : | D_loss : 0.418520 | G_loss : 1.710005\n",
      "Epoch   690 : | D_loss : 0.464482 | G_loss : 2.010629\n",
      "Epoch   695 : | D_loss : 0.488638 | G_loss : 1.437983\n",
      "Epoch   700 : | D_loss : 0.418109 | G_loss : 1.786599\n",
      "Epoch   705 : | D_loss : 0.356401 | G_loss : 1.423951\n",
      "Epoch   710 : | D_loss : 0.251357 | G_loss : 1.774289\n",
      "Epoch   715 : | D_loss : 0.462288 | G_loss : 1.328001\n",
      "Epoch   720 : | D_loss : 0.310313 | G_loss : 2.294254\n",
      "Epoch   725 : | D_loss : 0.193539 | G_loss : 2.478611\n",
      "Epoch   730 : | D_loss : 0.594954 | G_loss : 1.826319\n",
      "Epoch   735 : | D_loss : 0.611786 | G_loss : 2.600429\n",
      "Epoch   740 : | D_loss : 0.541115 | G_loss : 2.889608\n",
      "Epoch   745 : | D_loss : 0.273040 | G_loss : 1.857325\n",
      "Epoch   750 : | D_loss : 0.421599 | G_loss : 1.463685\n",
      "Epoch   755 : | D_loss : 0.450632 | G_loss : 1.779382\n",
      "Epoch   760 : | D_loss : 0.375729 | G_loss : 2.230953\n",
      "Epoch   765 : | D_loss : 0.322011 | G_loss : 1.561960\n",
      "Epoch   770 : | D_loss : 0.431889 | G_loss : 1.462921\n",
      "Epoch   775 : | D_loss : 0.223954 | G_loss : 2.821246\n",
      "Epoch   780 : | D_loss : 0.529884 | G_loss : 2.530875\n",
      "Epoch   785 : | D_loss : 0.510407 | G_loss : 2.074932\n",
      "Epoch   790 : | D_loss : 0.410448 | G_loss : 2.039245\n",
      "Epoch   795 : | D_loss : 0.456753 | G_loss : 1.332745\n",
      "Epoch   800 : | D_loss : 0.630225 | G_loss : 1.584864\n",
      "Epoch   805 : | D_loss : 0.302547 | G_loss : 2.024205\n",
      "Epoch   810 : | D_loss : 0.386317 | G_loss : 1.662106\n",
      "Epoch   815 : | D_loss : 0.605891 | G_loss : 1.939061\n",
      "Epoch   820 : | D_loss : 0.569259 | G_loss : 1.830878\n",
      "Epoch   825 : | D_loss : 0.632088 | G_loss : 1.999916\n",
      "Epoch   830 : | D_loss : 0.258202 | G_loss : 2.000135\n",
      "Epoch   835 : | D_loss : 0.348339 | G_loss : 3.345585\n",
      "Epoch   840 : | D_loss : 0.369729 | G_loss : 1.922264\n",
      "Epoch   845 : | D_loss : 0.472000 | G_loss : 1.611175\n",
      "Epoch   850 : | D_loss : 0.281082 | G_loss : 2.351353\n",
      "Epoch   855 : | D_loss : 0.405616 | G_loss : 2.229613\n",
      "Epoch   860 : | D_loss : 0.572951 | G_loss : 2.011979\n",
      "Epoch   865 : | D_loss : 0.213743 | G_loss : 2.580483\n",
      "Epoch   870 : | D_loss : 0.561253 | G_loss : 2.041847\n",
      "Epoch   875 : | D_loss : 0.290318 | G_loss : 2.246203\n",
      "Epoch   880 : | D_loss : 0.341750 | G_loss : 1.754211\n",
      "Epoch   885 : | D_loss : 0.428975 | G_loss : 1.835357\n",
      "Epoch   890 : | D_loss : 0.623795 | G_loss : 1.258744\n",
      "Epoch   895 : | D_loss : 0.400054 | G_loss : 1.929571\n",
      "Epoch   900 : | D_loss : 0.420200 | G_loss : 2.342610\n",
      "Epoch   905 : | D_loss : 0.252982 | G_loss : 3.202509\n",
      "Epoch   910 : | D_loss : 0.451719 | G_loss : 1.504018\n",
      "Epoch   915 : | D_loss : 0.269344 | G_loss : 2.075541\n",
      "Epoch   920 : | D_loss : 0.262767 | G_loss : 2.038672\n",
      "Epoch   925 : | D_loss : 0.321673 | G_loss : 2.030692\n",
      "Epoch   930 : | D_loss : 0.341961 | G_loss : 2.387640\n",
      "Epoch   935 : | D_loss : 0.353323 | G_loss : 1.809947\n",
      "Epoch   940 : | D_loss : 0.382762 | G_loss : 2.701356\n",
      "Epoch   945 : | D_loss : 0.239036 | G_loss : 2.631444\n",
      "Epoch   950 : | D_loss : 0.557320 | G_loss : 2.374847\n",
      "Epoch   955 : | D_loss : 0.302875 | G_loss : 3.066162\n",
      "Epoch   960 : | D_loss : 0.334040 | G_loss : 2.407568\n",
      "Epoch   965 : | D_loss : 0.262814 | G_loss : 3.002484\n",
      "Epoch   970 : | D_loss : 0.277790 | G_loss : 3.193126\n",
      "Epoch   975 : | D_loss : 0.244000 | G_loss : 2.493916\n",
      "Epoch   980 : | D_loss : 0.194829 | G_loss : 2.670137\n",
      "Epoch   985 : | D_loss : 0.237931 | G_loss : 2.465641\n",
      "Epoch   990 : | D_loss : 0.274646 | G_loss : 2.400004\n",
      "Epoch   995 : | D_loss : 0.452778 | G_loss : 2.499675\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 1000\n",
    "for epoch in range(max_epochs):\n",
    "    D.train()\n",
    "    G.train()\n",
    "    for real_img, _ in trainloader:\n",
    "        n_data = real_img.shape[0]\n",
    "\n",
    "        # Real dan Fake Images\n",
    "        real_img = real_img.to(device)\n",
    "        fake_image = G.generate(n_data, device)\n",
    "        # Real dan Fake Labels\n",
    "        real = torch.ones((n_data, 1), device=device)\n",
    "        fake = torch.zeros((n_data, 1), device=device)\n",
    "        # Training Discriminator\n",
    "        d_optimizer.zero_grad()\n",
    "        ## Real Image -> Discriminator -> Label Real\n",
    "        output = D(real_img)\n",
    "        d_real_loss = criterion(output, real)\n",
    "        ## Fake Image -> Discriminator -> Label Fake\n",
    "        output = D(fake_image.detach())\n",
    "        d_fake_loss = criterion(output, fake)\n",
    "\n",
    "        d_loss = d_real_loss + d_fake_loss\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        \n",
    "        # Training Generator\n",
    "        g_optimizer.zero_grad()\n",
    "        ## Fake Image -> Discriminator -> tapi Label Real\n",
    "        output = D(fake_image)\n",
    "        g_loss = criterion(output, real)\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"Epoch {epoch:5} : | D_loss : {d_loss/2:5f} | G_loss : {g_loss:5f}\")\n",
    "    if epoch % 15 == 0:\n",
    "        G.eval()\n",
    "        epoch = str(epoch).zfill(4)\n",
    "        fake_image = G.generate(64, device=device)\n",
    "        save_image(fake_image.view(-1, 1, 28, 28), f\"output/GAN/{epoch}.jpg\", nrow=8, normalize=True)\n",
    "\n",
    "        torch.save(D, \"model/GAN/discriminator.pth\")\n",
    "        torch.save(G, \"model/GAN/generator.pth\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee6771f-e71e-4edf-86f1-d0301bd4bf15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8777a3e-8148-4f3c-905f-6f06b3a988c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MachineLearning] *",
   "language": "python",
   "name": "conda-env-MachineLearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
