{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08b3a498-6b7a-42e6-9cd9-fbb865ab47b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "sw_indo = stopwords.words('indonesian') + list(punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd10495-81b0-411f-8211-d6371b152b13",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c645be44-fc05-417e-89b7-9a2c9c0eabd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ginandjar Tetap Ditahan. Jaksa Agung Dilaporka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jakarta Dikangkangi Para Preman\\nKALAU tak pun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Penyimpangan di Setpres Seolah Terjadi Sekaran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dibayarkan, Rapel Kenaikan Gaji Pegawai Pos\\nK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Kekerasan, Elite agar Duduk Bersama\\nSeju...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                teks\n",
       "0  Ginandjar Tetap Ditahan. Jaksa Agung Dilaporka...\n",
       "1  Jakarta Dikangkangi Para Preman\\nKALAU tak pun...\n",
       "2  Penyimpangan di Setpres Seolah Terjadi Sekaran...\n",
       "3  Dibayarkan, Rapel Kenaikan Gaji Pegawai Pos\\nK...\n",
       "4  Stop Kekerasan, Elite agar Duduk Bersama\\nSeju..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/kompas.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ad7367-9cf9-4a21-ab98-2d9a48e93717",
   "metadata": {},
   "source": [
    "# Extract BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d29b8a7-f6df-4cc3-913f-3fdb3492439d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f275f95c-90f8-4e94-964a-e4da1deac094",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer(ngram_range=(1, 2), tokenizer=word_tokenize, stop_words=sw_indo, min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64dc99e9-9833-4f2c-ab4a-67a51412423e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zaens/miniconda3/envs/MachineLearning/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/zaens/miniconda3/envs/MachineLearning/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "bow_matrix = bow.fit_transform(df.teks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f4d40c-01a9-4907-bf4b-de51cc861ed1",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94acb5fb-3d28-43e0-9933-71616081c96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = bow.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d234e9ad-7386-4351-be60-5ef0ea929055",
   "metadata": {},
   "source": [
    "## Latent Semantic Analysis (LSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59cf596b-4559-42a9-b718-fd3b69b51901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25134"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6223909-a489-4317-b801-681c173ae7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e1567ab-f296-499b-a188-18cab3393e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa = TruncatedSVD(n_components=10, n_iter=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40c4ef57-aff5-4178-87f4-6cdbcd5aad3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_matrix = lsa.fit_transform(bow_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "973b6199-185c-4a9b-b588-fe62f0f9529d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2008, 25134)\n",
      "(2008, 10)\n",
      "(10, 25134)\n"
     ]
    }
   ],
   "source": [
    "print(bow_matrix.shape) # hidden\n",
    "print(lsa_matrix.shape) # weight / code\n",
    "print(lsa.components_.shape) # fitur / topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2063dee-d361-453f-bca2-a76e103d487a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topik(model):\n",
    "    return [[ vocab[idx] for idx in reversed(comp.argsort()[-6:]) if vocab[idx].isalnum()] for comp in model.components_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d211c156-e181-4294-9485-2a9102bfb7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['presiden', 'indonesia', 'pemerintah', 'dpr'],\n",
       " ['presiden', 'dpr', 'ketua', 'partai', 'mpr', 'tandjung'],\n",
       " ['pemerintah', 'rp', 'indonesia', 'bank', 'persen', 'utang'],\n",
       " ['presiden', 'indonesia', 'as', 'abdurrahman', 'wahid'],\n",
       " ['presiden', 'air', 'banjir', 'harga', 'rp', 'dpr'],\n",
       " ['harga', 'beras', 'rp', 'bbm'],\n",
       " ['mpr', 'konstitusi', 'bppn', 'uud'],\n",
       " ['indonesia', 'mpr', 'konstitusi', 'uud', 'perubahan', '1945'],\n",
       " ['pemerintah', 'dpr', 'israel', 'bppn', 'kota', 'aceh'],\n",
       " ['indonesia', 'pemerintah', 'dpr', 'beras', 'utang', 'air']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_topik(lsa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a1b1b3-0e86-4903-bb5f-0e14002c359d",
   "metadata": {},
   "source": [
    "## Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53a1b5bb-27d0-4427-ad8e-ff74ff59bbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c767f7d5-3d90-4a78-9d7e-920da745856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=10, max_iter=10, random_state=42)\n",
    "lda_matrix = lda.fit_transform(bow_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6405aa0-edd7-47a0-a06e-bf4bd21e14a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['tandjung', 'dpr', 'hukum', 'ketua'],\n",
       " ['bank', 'indonesia', 'pemerintah', 'ekonomi'],\n",
       " ['pesawat', 'orang', 'rumah', 'korban'],\n",
       " ['banjir', 'air', 'warga', 'jakarta', 'jalan'],\n",
       " ['tni', 'hukum', 'ginandjar', 'tim'],\n",
       " ['rp', 'pemerintah', 'harga', 'bppn'],\n",
       " ['indonesia', 'as', 'pemerintah', 'aceh'],\n",
       " ['presiden', 'dpr', 'politik', 'ketua'],\n",
       " ['daerah', 'indonesia', 'masyarakat', 'maluku'],\n",
       " ['polisi', 'kepala', 'jakarta', 'orang']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_topik(lda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MachineLearning] *",
   "language": "python",
   "name": "conda-env-MachineLearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
